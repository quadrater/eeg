{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1eea7e17-5ee4-46a0-941b-c3e3522794f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import scipy.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41634a71-6118-4443-90da-5d8d118a6ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = 6\n",
    "samples = 4096\n",
    "rate = 1024\n",
    "path = './Base de Datos Habla Imaginada'\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for root, _, files in os.walk(path):\n",
    "    for file in files:\n",
    "        if file.endswith('_EEG.mat'):\n",
    "            mat = scipy.io.loadmat(os.path.join(root, file))\n",
    "            # The format stores the per channel data + three labels.\n",
    "            data.append(mat['EEG'][:, :channels*samples].reshape(-1, channels, samples))\n",
    "            labels.append(mat['EEG'][:, channels*samples:])\n",
    "\n",
    "data = torch.from_numpy(np.concatenate(data, axis=0)).to(torch.float32)\n",
    "labels = torch.from_numpy(np.concatenate(labels, axis=0)).to(int)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "798f7021-a131-4305-93bc-d7eda08f8a75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([9315, 6, 4096]), torch.Size([9315, 3]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33393902-c020-4a6a-8373-3dea59648353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-13.2110, -11.7757, -10.2983,  ...,  -6.5553,  -6.2022,  -5.6591],\n",
       "         [ -2.7764,  -2.3330,  -1.8796,  ...,   2.8046,   2.3710,   1.7605],\n",
       "         [  3.6162,   3.7574,   3.8462,  ...,   0.8512,   0.8198,   0.6374],\n",
       "         [  6.7315,   6.5819,   6.4022,  ...,   7.1031,   6.9845,   6.7511],\n",
       "         [  6.8673,   7.1598,   7.4232,  ...,  -2.0913,  -1.7007,  -1.3703],\n",
       "         [  8.4799,   8.3454,   8.1901,  ...,   6.1206,   6.1089,   5.9817]]),\n",
       " tensor([1, 8, 2]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0], labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b1b44db-4d3e-4950-b5ca-f604d1ee74e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = {\n",
    "    \"channels\": channels,\n",
    "    \"channels_residual\": channels + 1, # Add residual\n",
    "    \"samples\": samples,\n",
    "    \"rate\": rate,\n",
    "    \"channel_names\": [a + n for a in \"FCP\" for n in \"34\"] + [\"residual\"],\n",
    "    \"stimuli\": [\"A\", \"E\", \"I\", \"O\", \"U\", \"Arriba\", \"Abajo\", \"Adelante\", \"Atras\", \"Derecha\", \"Izquierda\"],\n",
    "    \"modalities\": [\"Imagined\", \"Pronounced\"],\n",
    "    \"artifacts\": [\"None\", \"Blink\"]\n",
    "}\n",
    "\n",
    "dataset = {\n",
    "    \"data\": data,\n",
    "    \"labels\": labels - 1, # YOLO: make 0-based\n",
    "    \"metadata\": metadata\n",
    "}\n",
    "\n",
    "torch.save(dataset, \"dataset.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccc807d-adb2-4803-8a6c-4f817d8b5065",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
