{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1eea7e17-5ee4-46a0-941b-c3e3522794f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import scipy.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41634a71-6118-4443-90da-5d8d118a6ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = 6\n",
    "samples = 4096\n",
    "rate = 1024\n",
    "path = './Base de Datos Habla Imaginada'\n",
    "\n",
    "subjects = []\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for root, _, files in os.walk(path):\n",
    "    for file in files:\n",
    "        if file.endswith('_EEG.mat'):\n",
    "            mat = scipy.io.loadmat(os.path.join(root, file))\n",
    "            # The format stores the per channel data + three labels. Subject from filename.\n",
    "            subjects.append(torch.tensor([int(file[1:3])] * len(mat['EEG'])))\n",
    "            data.append(mat['EEG'][:, :channels*samples].reshape(-1, channels, samples))\n",
    "            labels.append(mat['EEG'][:, channels*samples:])\n",
    "\n",
    "subjects = torch.from_numpy(np.concatenate(subjects, axis=0)).to(int) \n",
    "data = torch.from_numpy(np.concatenate(data, axis=0)).to(torch.float32)\n",
    "labels = torch.from_numpy(np.concatenate(labels, axis=0)).to(int)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "798f7021-a131-4305-93bc-d7eda08f8a75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([9315]), torch.Size([9315, 6, 4096]), torch.Size([9315, 3]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjects.shape, data.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33393902-c020-4a6a-8373-3dea59648353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1),\n",
       " tensor([[-45.0273, -44.9023, -44.4957,  ...,  21.5850,  20.3604,  19.1752],\n",
       "         [-42.8867, -43.1319, -43.2460,  ...,  23.5990,  22.3516,  21.1756],\n",
       "         [-49.0815, -48.7082, -47.9301,  ...,  19.6565,  18.9825,  18.3849],\n",
       "         [-25.9682, -26.7065, -27.4165,  ...,  16.7802,  16.3765,  16.1537],\n",
       "         [-25.5519, -26.1960, -26.8182,  ...,  18.9174,  18.3165,  17.8039],\n",
       "         [-16.6065, -17.4099, -18.3053,  ...,  22.1402,  21.3476,  20.7603]]),\n",
       " tensor([1, 9, 2]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjects[0], data[0], labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b1b44db-4d3e-4950-b5ca-f604d1ee74e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = {\n",
    "    \"channels\": channels,\n",
    "    \"channels_residual\": channels + 1, # Add residual\n",
    "    \"samples\": samples,\n",
    "    \"rate\": rate,\n",
    "    \"channel_names\": [a + n for a in \"FCP\" for n in \"34\"] + [\"residual\"],\n",
    "    \"stimuli\": [\"A\", \"E\", \"I\", \"O\", \"U\", \"Arriba\", \"Abajo\", \"Adelante\", \"Atras\", \"Derecha\", \"Izquierda\"],\n",
    "    \"modalities\": [\"Imagined\", \"Pronounced\"],\n",
    "    \"artifacts\": [\"None\", \"Blink\"],\n",
    "    \"label_headers\": [\"modality\", \"stimulus\", \"artifact\"]\n",
    "}\n",
    "\n",
    "dataset = {\n",
    "    \"data\": data,\n",
    "    \"labels\": labels - 1, # YOLO: make 0-based\n",
    "    \"metadata\": metadata,\n",
    "    \"subjects\": subjects - 1, # YOLO: make 0-based\n",
    "}\n",
    "\n",
    "torch.save(dataset, \"dataset.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ccc807d-adb2-4803-8a6c-4f817d8b5065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-45.0273, -44.9023, -44.4957,  ...,  21.5850,  20.3604,  19.1752])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b339a19f-24cf-4864-94ee-fcfa5d01d09c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
