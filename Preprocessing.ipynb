{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1eea7e17-5ee4-46a0-941b-c3e3522794f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import scipy.io\n",
    "import scipy.signal\n",
    "import picard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de5bb0db-ee52-47b8-b736-6ff86162bdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "show = __name__ == \"__main__\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8dd319a8-0ea1-4159-8255-aeaf94d193e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torch.load(\"dataset.pt\", weights_only=True)\n",
    "\n",
    "# Import the relevant metadata\n",
    "for key, value in dataset[\"metadata\"].items():\n",
    "    locals()[key] = value\n",
    "\n",
    "data = dataset['data']\n",
    "labels = dataset['labels']\n",
    "\n",
    "for key, value in dataset[\"metadata\"].items():\n",
    "    locals()[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13ed0791-afd4-49b4-a8ad-4fff5a1b639d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data, dim=None):\n",
    "    means = data.mean(dim=dim, keepdim=True)\n",
    "    stds = data.std(dim=dim, keepdim=True)\n",
    "    data -= means\n",
    "    data /= stds\n",
    "    return data\n",
    "    \n",
    "if show:\n",
    "    data_normal = normalize(data, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbe9da88-31cb-45ae-a75c-150d88cbe8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_average_referencing(data, dim=None, residual=False):\n",
    "    means = data.mean(dim=dim, keepdim=True)\n",
    "    data -= means\n",
    "    if residual:\n",
    "        return torch.cat([data, means], dim=dim)\n",
    "    return data\n",
    "\n",
    "if show:\n",
    "    data_car = common_average_referencing(data, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf0a315e-739e-401a-bfe2-aafed4d96f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9315, 6, 4096])\n"
     ]
    }
   ],
   "source": [
    "if show:\n",
    "    data_normal_car = normalize(common_average_referencing(data, dim=1), dim=2)\n",
    "    print(data_normal_car.shape)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a65ed2c5-f2f9-4959-b845-fb1c18fdadae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Super naive spike thesholdning. Everything beyond +/- 1 SD is a spike.\n",
    "def abs_threshold(data, threshold=1):\n",
    "    return (data.abs() > 1).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f92d120f-92a4-4a17-85c3-b52783403d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9315, 6, 4096])\n"
     ]
    }
   ],
   "source": [
    "if show:\n",
    "    spikes = abs_threshold(data_normal_car, threshold=1)\n",
    "    print(spikes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fe9403d-c172-4b2c-9ade-e0c875989e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 0.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 1., 1., 0.],\n",
      "         [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 1., 1., 1.],\n",
      "         [0., 0., 0.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 1., 1., 1.],\n",
      "         [0., 0., 0.,  ..., 1., 1., 1.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [0., 0., 0.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 1., 1.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 0.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "if show:\n",
    "    print(spikes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40a81164-3b54-4a3e-b375-20d80271c04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive spike thesholdning. Everything beyond +/- 1 SD is a spike.\n",
    "def pol_threshold(data, threshold=1, dim=1):\n",
    "    return torch.cat(((data > threshold).float(), (data < -threshold).float()), dim=dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9a65ff6-c89e-4151-baaa-f2e0985646ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "if show:\n",
    "    spikes_pol = pol_threshold(data_normal_car, threshold=1, dim=1)\n",
    "    spikes_pol.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2abe14ab-3331-4d4c-8bac-78af7978316a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delta_coding(data, delta=0.1):\n",
    "    diff = torch.diff(data, dim=2, prepend=data[:,:,:1])\n",
    "    spikes_diff = (diff / delta).to(int)\n",
    "    # This wasn't exactly obvious. floor(1.5) is 1 while floor (-1.5) is -2\n",
    "    spikes_delta = torch.cat((\n",
    "        torch.floor(spikes_diff).clamp(min=0),\n",
    "        -torch.ceil(spikes_diff).clamp(max=0),\n",
    "    ), dim=1).to(torch.float32)\n",
    "    return spikes_delta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8c67a71-01d7-4fde-afa3-47f181c9ac80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9315, 12, 4096])\n"
     ]
    }
   ],
   "source": [
    "if show:\n",
    "    spikes_delta = delta_coding(data_normal_car, delta=0.1)\n",
    "    print(spikes_delta.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a007a1a-c31b-4012-b66a-33ba815d5903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 2., 2., 2., 2., 2., 2., 2., 2., 2., 1., 1., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        1., 1., 1., 1., 1., 2., 2., 2., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "if show:\n",
    "    print(spikes_delta[0,0,1000:1100], spikes_delta[0,7,1000:1100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0759e77-a51c-41da-937b-b787ec56f5ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(855.) tensor(650.)\n"
     ]
    }
   ],
   "source": [
    "if show:\n",
    "    print(spikes_delta[0,0,:].sum(), spikes_delta[0,7,:].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6f0eb5e-4080-47f1-9db3-e29c23870ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rate_coding(data, sensitivity=0.1):\n",
    "    spikes_quant = data / sensitivity\n",
    "    spikes_rate = torch.cat((\n",
    "        torch.floor(spikes_quant).clamp(min=0),\n",
    "        -torch.ceil(spikes_quant).clamp(max=0),\n",
    "    ), dim=1).to(int).to(torch.float32)\n",
    "    return spikes_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b795547-52a8-4991-a21f-7348654f397b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(15121.) tensor(15308.)\n"
     ]
    }
   ],
   "source": [
    "if show:\n",
    "    spikes_rate = rate_coding(data_normal_car, sensitivity=0.1)\n",
    "    print(spikes_rate[0,0,:].sum(), spikes_rate[0,7,:].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8f81971-055b-47b3-9e4f-0191d2059121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9315, 12, 4096])\n"
     ]
    }
   ],
   "source": [
    "if show:\n",
    "    print(spikes_rate.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62f16755-1fdf-4d84-ae5c-f0b41f3f4fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "if show:\n",
    "    spikes_rate[0,0,1000:1100], spikes_rate[0,7,1000:1100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82559670-0e49-4506-aa51-de1f9349f4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_sum(data, size, dim=-1):\n",
    "    '''Bin the data into fewer bins by summation, analogous to Tonic.ToFrame. Implementation by ChatGPT.'''\n",
    "    total_indices = data.size(dim)\n",
    "    quotient, remainder = divmod(total_indices, size)\n",
    "    bin_sizes = [quotient + (1 if i >= size - remainder else 0) for i in range(size)]\n",
    "    splits = torch.split(torch.arange(total_indices), bin_sizes)\n",
    "    return torch.stack([data.index_select(dim, idx).sum(dim=dim) for idx in splits], dim=dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eda1e3fa-3e58-4c7b-b097-536676f9d748",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(batch):\n",
    "    events, targets = zip(*batch)\n",
    "    events = torch.stack(events).permute(2, 0, 1)\n",
    "    targets = torch.tensor(targets)\n",
    "    return events, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c258e4d-826c-43de-bca0-177cd758fac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(data, in_rate=rate, out_rate=rate//8):\n",
    "    samples = data.size(-1) * out_rate // in_rate\n",
    "    result = scipy.signal.resample(data.numpy(), samples, axis=-1)\n",
    "    return torch.tensor(result, device=data.device, dtype=data.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce05654c-52bc-4b2e-8b59-6d6d216ba881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9315, 6, 512]) tensor([[[-1.7901, -1.2316, -0.2249,  ..., -0.4548, -0.1657, -0.8302],\n",
      "         [-0.7497, -1.2089, -0.7197,  ...,  0.2524,  0.0408,  0.4718],\n",
      "         [ 0.1546, -0.2013, -1.2267,  ..., -0.2937, -0.8689, -0.4492],\n",
      "         [ 1.6666,  0.2609, -0.1395,  ...,  2.1496,  2.2918,  2.3698],\n",
      "         [ 0.5850,  2.0446,  1.3731,  ..., -1.4338, -1.6507, -1.8923],\n",
      "         [ 1.6648,  1.1493,  1.0155,  ...,  0.6244,  1.0931,  1.4547]],\n",
      "\n",
      "        [[-0.1296,  0.3201, -0.0952,  ...,  0.2230, -0.2758, -1.3174],\n",
      "         [-1.2068, -1.2258, -1.0657,  ...,  0.2338, -0.4884, -0.7140],\n",
      "         [ 0.0492,  1.0897,  1.3169,  ...,  0.5872,  0.8851, -0.2034],\n",
      "         [-0.4806, -0.6937, -1.0926,  ..., -0.1032, -0.9620, -0.8518],\n",
      "         [ 1.2148,  0.9044,  0.7386,  ..., -0.1825,  0.8674,  1.8076],\n",
      "         [ 0.3329, -0.4422,  0.1485,  ..., -0.6295, -0.0833,  1.0682]],\n",
      "\n",
      "        [[ 1.3713,  0.3089, -0.2299,  ...,  2.9085,  2.2313,  1.8590],\n",
      "         [ 0.9662,  0.3754,  0.6685,  ...,  1.1774,  0.4879,  1.1276],\n",
      "         [-0.4425, -0.5048, -0.2340,  ..., -0.3227, -0.5924, -0.5883],\n",
      "         [-0.6524,  0.6423,  0.5931,  ..., -1.2600,  0.0395, -0.5513],\n",
      "         [-1.4468, -1.0610, -0.8830,  ..., -3.0112, -2.3957, -2.0133],\n",
      "         [-0.7010,  0.2900,  0.3806,  ..., -1.2481, -0.8156, -0.9469]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.6912,  0.4729,  0.3652,  ..., -0.4599, -1.0037, -0.2536],\n",
      "         [ 0.0305,  0.3846, -0.3837,  ..., -0.9738, -1.6334, -1.5192],\n",
      "         [-0.8154, -1.0557, -0.3548,  ...,  0.0158, -0.3421, -0.2051],\n",
      "         [-0.2383,  1.2028,  0.3906,  ...,  0.2717, -0.0862, -1.4168],\n",
      "         [ 0.0354, -1.1412, -0.1435,  ...,  1.0024,  1.7663,  2.3263],\n",
      "         [ 0.0639,  0.4195,  0.1563,  ...,  0.0287,  0.8055,  0.2033]],\n",
      "\n",
      "        [[-1.6019, -2.7578, -1.3270,  ...,  2.0451,  0.8733,  0.1474],\n",
      "         [ 0.4905,  0.6656,  0.0492,  ...,  0.6338,  1.1137,  1.1003],\n",
      "         [-0.3561, -1.4086, -0.0950,  ..., -0.4733, -0.3751,  0.9242],\n",
      "         [-0.1166,  0.5155, -0.5160,  ..., -1.3673, -1.0102, -1.5744],\n",
      "         [ 1.3232,  2.3769,  2.0724,  ..., -0.3279, -0.2706,  0.0154],\n",
      "         [ 0.2497,  0.6028, -0.3905,  ..., -1.0834, -0.6548, -0.8067]],\n",
      "\n",
      "        [[-0.0825, -0.2908,  0.0548,  ...,  0.8275,  0.3917,  0.2228],\n",
      "         [-0.1235,  0.3237,  0.4651,  ...,  0.3619,  0.9666,  0.7072],\n",
      "         [ 0.2111, -1.5614, -1.6469,  ...,  2.0298,  1.3807,  1.0165],\n",
      "         [ 0.1815,  0.6937,  0.8239,  ..., -1.5546, -0.8986, -0.1389],\n",
      "         [ 0.0523,  0.1525, -0.6557,  ...,  0.0079, -0.3877, -0.8675],\n",
      "         [-0.1745,  0.6241,  0.9120,  ..., -1.8570, -1.5698, -0.8948]]])\n"
     ]
    }
   ],
   "source": [
    "if show:\n",
    "    data_downsampled = downsample(data)\n",
    "    print(data_downsampled.shape, data_downsampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "15910017-71e7-4f44-bd43-27b953f9ad58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Never mind the warnings...\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"sklearn.base\")\n",
    "\n",
    "def ica(data, max_iter=1000, tol=1e-6):\n",
    "    results = []\n",
    "    for d in data:\n",
    "        d = d.transpose(0, 1)\n",
    "        transform = picard.Picard(d.size(1), max_iter=1000, tol=1e-6)\n",
    "        result = torch.tensor(transform.fit_transform(d),\n",
    "                              dtype=data.dtype,\n",
    "                              device=data.device).transpose(0, 1)\n",
    "        results.append(result)\n",
    "    return torch.stack(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca265cda-d025-47fa-b5de-c783afc2d904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9315, 6, 512]) tensor([[ 0.0487,  0.0110,  0.0087,  ...,  0.0895,  0.0958,  0.0701],\n",
      "        [-0.0147,  0.0422,  0.0121,  ..., -0.0499, -0.0700, -0.0898],\n",
      "        [ 0.0301, -0.0083, -0.0138,  ...,  0.0391,  0.0493,  0.0671],\n",
      "        [ 0.0681,  0.0864,  0.0459,  ..., -0.0284, -0.0232, -0.0106],\n",
      "        [ 0.0242,  0.0214,  0.0331,  ...,  0.0227,  0.0100,  0.0186],\n",
      "        [ 0.0208, -0.0313, -0.0808,  ...,  0.0158, -0.0082,  0.0301]])\n"
     ]
    }
   ],
   "source": [
    "if show:\n",
    "    y = ica(data_downsampled)\n",
    "    print(y.shape, y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7d99ad66-9ac7-42cf-89c3-8b4df28783d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This was provided by o1 based on the disussion here:\n",
    "# https://chatgpt.com/share/67669e9c-ebd8-8007-92f0-70579f58cc9a\n",
    "\n",
    "def ica_fit_and_transform(\n",
    "    data: torch.Tensor,      # shape [N, C, T]\n",
    "    train_mask: torch.Tensor,# shape [N], boolean or long indices\n",
    "    max_iter: int = 1000,\n",
    "    tol: float = 1e-6\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Learn a single ICA decomposition on all training-set trials, \n",
    "    then apply that unmixing to the entire dataset.\n",
    "\n",
    "    Args:\n",
    "        data (torch.Tensor): \n",
    "            EEG data of shape [num_trials, num_channels, num_timepoints].\n",
    "        train_mask (torch.Tensor): \n",
    "            Boolean or index mask of shape [num_trials] indicating which trials are training.\n",
    "        max_iter (int): \n",
    "            Maximum number of Picard iterations.\n",
    "        tol (float): \n",
    "            Tolerance for the stopping criterion in Picard.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: \n",
    "            ICA-transformed data of shape [num_trials, num_channels, num_timepoints].\n",
    "            Each trial has the same shape as input but in the ICA component space.\n",
    "    \"\"\"\n",
    "\n",
    "    device = data.device\n",
    "    dtype = data.dtype\n",
    "\n",
    "    # ------------------------------------------\n",
    "    # 1) EXTRACT & CONCATENATE ALL TRAINING TRIALS\n",
    "    # ------------------------------------------\n",
    "    # data[train_mask] has shape [n_train, C, T]\n",
    "    train_data = data[train_mask]\n",
    "    n_train, C, T = train_data.shape\n",
    "\n",
    "    # We want shape [n_samples, n_features] = [n_train*T, C]\n",
    "    # So permute to [n_train, T, C], then reshape\n",
    "    # => shape [n_train*T, C]\n",
    "    train_data_2d = train_data.permute(0, 2, 1).reshape(-1, C)\n",
    "\n",
    "    # Move to CPU if necessary, because Picard typically runs on NumPy\n",
    "    train_data_np = train_data_2d.cpu().numpy()\n",
    "\n",
    "    # ------------------------------------------\n",
    "    # 2) FIT ICA ON ALL TRAINING DATA\n",
    "    # ------------------------------------------\n",
    "    ica_transform = picard.Picard(\n",
    "        n_components=C, \n",
    "        max_iter=max_iter, \n",
    "        tol=tol\n",
    "    )\n",
    "    ica_transform.fit(train_data_np)\n",
    "\n",
    "    # ------------------------------------------\n",
    "    # 3) APPLY ICA TO ALL TRIALS (TRAIN/VAL/TEST)\n",
    "    # ------------------------------------------\n",
    "    results = []\n",
    "    N = data.shape[0]\n",
    "    for i in range(N):\n",
    "        # Each trial: shape [C, T]\n",
    "        trial = data[i]  \n",
    "        # Transpose to [T, C] for transform()\n",
    "        trial_t = trial.transpose(0, 1).cpu().numpy()\n",
    "\n",
    "        # Transform with the learned unmixing\n",
    "        trial_ica = ica_transform.transform(trial_t)  \n",
    "        # => shape [T, C]\n",
    "\n",
    "        # Convert back to Torch, and transpose to [C, T] if desired\n",
    "        trial_ica_torch = torch.tensor(\n",
    "            trial_ica, dtype=dtype, device=device\n",
    "        ).transpose(0, 1)\n",
    "\n",
    "        results.append(trial_ica_torch)\n",
    "\n",
    "    # Stack back into [N, C, T]\n",
    "    return torch.stack(results, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "acfb4c52-cca2-4e40-82bb-ba3e546e328e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9315, 6, 512]) tensor([[ 1.9342e-03,  1.8477e-03,  9.6474e-04,  ...,  2.5228e-04,\n",
      "          2.2555e-04,  5.1232e-04],\n",
      "        [-3.1731e-04,  2.6800e-04,  5.7187e-05,  ..., -9.6826e-04,\n",
      "         -1.2349e-03, -1.0908e-03],\n",
      "        [ 7.8944e-04,  5.3633e-04,  3.4691e-04,  ...,  4.4177e-04,\n",
      "          4.8870e-04,  6.2089e-04],\n",
      "        [ 2.7772e-04, -5.8648e-05, -3.2079e-04,  ...,  2.3449e-05,\n",
      "         -2.9228e-04,  2.8470e-04],\n",
      "        [-2.0965e-04,  2.6938e-04,  8.5743e-05,  ..., -8.0569e-05,\n",
      "         -2.9396e-04, -7.5603e-04],\n",
      "        [-4.2167e-04,  5.4104e-04,  1.1099e-03,  ..., -7.1850e-04,\n",
      "         -4.5368e-04, -8.4454e-04]])\n"
     ]
    }
   ],
   "source": [
    "if show:\n",
    "    train_mask = torch.rand((len(data_downsampled),)) < 0.8\n",
    "    z = ica_fit_and_transform(data_downsampled, train_mask=train_mask)\n",
    "    print(z.shape, z[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ab1956-bbdf-42e9-ad36-19c2f22dc185",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
