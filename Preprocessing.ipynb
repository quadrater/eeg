{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1eea7e17-5ee4-46a0-941b-c3e3522794f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import scipy.io\n",
    "import scipy.signal\n",
    "import picard\n",
    "import sklearn.preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "de5bb0db-ee52-47b8-b736-6ff86162bdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "show = __name__ == \"__main__\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8dd319a8-0ea1-4159-8255-aeaf94d193e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torch.load(\"dataset.pt\", weights_only=True)\n",
    "\n",
    "# Import the relevant metadata\n",
    "for key, value in dataset[\"metadata\"].items():\n",
    "    locals()[key] = value\n",
    "\n",
    "data = dataset['data']\n",
    "labels = dataset['labels']\n",
    "\n",
    "for key, value in dataset[\"metadata\"].items():\n",
    "    locals()[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "13ed0791-afd4-49b4-a8ad-4fff5a1b639d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data, dim=None):\n",
    "    means = data.mean(dim=dim, keepdim=True)\n",
    "    stds = data.std(dim=dim, keepdim=True)\n",
    "    data -= means\n",
    "    data /= stds\n",
    "    return data\n",
    "    \n",
    "if show:\n",
    "    data_normal = normalize(data, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fbe9da88-31cb-45ae-a75c-150d88cbe8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_average_referencing(data, dim=None, residual=False):\n",
    "    means = data.mean(dim=dim, keepdim=True)\n",
    "    data -= means\n",
    "    if residual:\n",
    "        return torch.cat([data, means], dim=dim)\n",
    "    return data\n",
    "\n",
    "if show:\n",
    "    data_car = common_average_referencing(data, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bf0a315e-739e-401a-bfe2-aafed4d96f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9315, 6, 4096])\n"
     ]
    }
   ],
   "source": [
    "if show:\n",
    "    data_normal_car = normalize(common_average_referencing(data, dim=1), dim=2)\n",
    "    print(data_normal_car.shape)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a65ed2c5-f2f9-4959-b845-fb1c18fdadae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Super naive spike thesholdning. Everything beyond +/- 1 SD is a spike.\n",
    "def abs_threshold(data, threshold=1):\n",
    "    return (data.abs() > 1).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f92d120f-92a4-4a17-85c3-b52783403d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9315, 6, 4096])\n"
     ]
    }
   ],
   "source": [
    "if show:\n",
    "    spikes = abs_threshold(data_normal_car, threshold=1)\n",
    "    print(spikes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2fe9403d-c172-4b2c-9ade-e0c875989e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 0.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 1., 1., 0.],\n",
      "         [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 1., 1., 1.],\n",
      "         [0., 0., 0.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 1., 1., 1.],\n",
      "         [0., 0., 0.,  ..., 1., 1., 1.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [0., 0., 0.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 1., 1.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 0.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "if show:\n",
    "    print(spikes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "40a81164-3b54-4a3e-b375-20d80271c04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive spike thesholdning. Everything beyond +/- 1 SD is a spike.\n",
    "def pol_threshold(data, threshold=1, dim=1):\n",
    "    return torch.cat(((data > threshold).float(), (data < -threshold).float()), dim=dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d9a65ff6-c89e-4151-baaa-f2e0985646ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "if show:\n",
    "    spikes_pol = pol_threshold(data_normal_car, threshold=1, dim=1)\n",
    "    spikes_pol.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2abe14ab-3331-4d4c-8bac-78af7978316a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delta_coding(data, delta=0.1):\n",
    "    diff = torch.diff(data, dim=2, prepend=data[:,:,:1])\n",
    "    spikes_diff = (diff / delta).to(int)\n",
    "    # This wasn't exactly obvious. floor(1.5) is 1 while floor (-1.5) is -2\n",
    "    spikes_delta = torch.cat((\n",
    "        torch.floor(spikes_diff).clamp(min=0),\n",
    "        -torch.ceil(spikes_diff).clamp(max=0),\n",
    "    ), dim=1).to(torch.float32)\n",
    "    return spikes_delta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d8c67a71-01d7-4fde-afa3-47f181c9ac80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9315, 12, 4096])\n"
     ]
    }
   ],
   "source": [
    "if show:\n",
    "    spikes_delta = delta_coding(data_normal_car, delta=0.1)\n",
    "    print(spikes_delta.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6a007a1a-c31b-4012-b66a-33ba815d5903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 2., 2., 2., 2., 2., 2., 2., 2., 2., 1., 1., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        1., 1., 1., 1., 1., 2., 2., 2., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "if show:\n",
    "    print(spikes_delta[0,0,1000:1100], spikes_delta[0,7,1000:1100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d0759e77-a51c-41da-937b-b787ec56f5ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(855.) tensor(650.)\n"
     ]
    }
   ],
   "source": [
    "if show:\n",
    "    print(spikes_delta[0,0,:].sum(), spikes_delta[0,7,:].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c6f0eb5e-4080-47f1-9db3-e29c23870ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rate_coding(data, sensitivity=0.1):\n",
    "    spikes_quant = data / sensitivity\n",
    "    spikes_rate = torch.cat((\n",
    "        torch.floor(spikes_quant).clamp(min=0),\n",
    "        -torch.ceil(spikes_quant).clamp(max=0),\n",
    "    ), dim=1).to(int).to(torch.float32)\n",
    "    return spikes_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2b795547-52a8-4991-a21f-7348654f397b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(15121.) tensor(15308.)\n"
     ]
    }
   ],
   "source": [
    "if show:\n",
    "    spikes_rate = rate_coding(data_normal_car, sensitivity=0.1)\n",
    "    print(spikes_rate[0,0,:].sum(), spikes_rate[0,7,:].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d8f81971-055b-47b3-9e4f-0191d2059121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9315, 12, 4096])\n"
     ]
    }
   ],
   "source": [
    "if show:\n",
    "    print(spikes_rate.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "62f16755-1fdf-4d84-ae5c-f0b41f3f4fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "if show:\n",
    "    spikes_rate[0,0,1000:1100], spikes_rate[0,7,1000:1100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "82559670-0e49-4506-aa51-de1f9349f4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_sum(data, size, dim=-1):\n",
    "    '''Bin the data into fewer bins by summation, analogous to Tonic.ToFrame. Implementation by ChatGPT.'''\n",
    "    total_indices = data.size(dim)\n",
    "    quotient, remainder = divmod(total_indices, size)\n",
    "    bin_sizes = [quotient + (1 if i >= size - remainder else 0) for i in range(size)]\n",
    "    splits = torch.split(torch.arange(total_indices), bin_sizes)\n",
    "    return torch.stack([data.index_select(dim, idx).sum(dim=dim) for idx in splits], dim=dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "eda1e3fa-3e58-4c7b-b097-536676f9d748",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(batch):\n",
    "    events, targets = zip(*batch)\n",
    "    events = torch.stack(events).permute(2, 0, 1)\n",
    "    targets = torch.tensor(targets)\n",
    "    return events, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8c258e4d-826c-43de-bca0-177cd758fac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(data, in_rate=rate, out_rate=rate//8):\n",
    "    samples = data.size(-1) * out_rate // in_rate\n",
    "    result = scipy.signal.resample(data.numpy(), samples, axis=-1)\n",
    "    return torch.tensor(result, device=data.device, dtype=data.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ce05654c-52bc-4b2e-8b59-6d6d216ba881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9315, 6, 512]) tensor([[[-1.7901, -1.2316, -0.2249,  ..., -0.4548, -0.1657, -0.8302],\n",
      "         [-0.7497, -1.2089, -0.7197,  ...,  0.2524,  0.0408,  0.4718],\n",
      "         [ 0.1546, -0.2013, -1.2267,  ..., -0.2937, -0.8689, -0.4492],\n",
      "         [ 1.6666,  0.2609, -0.1395,  ...,  2.1496,  2.2918,  2.3698],\n",
      "         [ 0.5850,  2.0446,  1.3731,  ..., -1.4338, -1.6507, -1.8923],\n",
      "         [ 1.6648,  1.1493,  1.0155,  ...,  0.6244,  1.0931,  1.4547]],\n",
      "\n",
      "        [[-0.1296,  0.3201, -0.0952,  ...,  0.2230, -0.2758, -1.3174],\n",
      "         [-1.2068, -1.2258, -1.0657,  ...,  0.2338, -0.4884, -0.7140],\n",
      "         [ 0.0492,  1.0897,  1.3169,  ...,  0.5872,  0.8851, -0.2034],\n",
      "         [-0.4806, -0.6937, -1.0926,  ..., -0.1032, -0.9620, -0.8518],\n",
      "         [ 1.2148,  0.9044,  0.7386,  ..., -0.1825,  0.8674,  1.8076],\n",
      "         [ 0.3329, -0.4422,  0.1485,  ..., -0.6295, -0.0833,  1.0682]],\n",
      "\n",
      "        [[ 1.3713,  0.3089, -0.2299,  ...,  2.9085,  2.2313,  1.8590],\n",
      "         [ 0.9662,  0.3754,  0.6685,  ...,  1.1774,  0.4879,  1.1276],\n",
      "         [-0.4425, -0.5048, -0.2340,  ..., -0.3227, -0.5924, -0.5883],\n",
      "         [-0.6524,  0.6423,  0.5931,  ..., -1.2600,  0.0395, -0.5513],\n",
      "         [-1.4468, -1.0610, -0.8830,  ..., -3.0112, -2.3957, -2.0133],\n",
      "         [-0.7010,  0.2900,  0.3806,  ..., -1.2481, -0.8156, -0.9469]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.6912,  0.4729,  0.3652,  ..., -0.4599, -1.0037, -0.2536],\n",
      "         [ 0.0305,  0.3846, -0.3837,  ..., -0.9738, -1.6334, -1.5192],\n",
      "         [-0.8154, -1.0557, -0.3548,  ...,  0.0158, -0.3421, -0.2051],\n",
      "         [-0.2383,  1.2028,  0.3906,  ...,  0.2717, -0.0862, -1.4168],\n",
      "         [ 0.0354, -1.1412, -0.1435,  ...,  1.0024,  1.7663,  2.3263],\n",
      "         [ 0.0639,  0.4195,  0.1563,  ...,  0.0287,  0.8055,  0.2033]],\n",
      "\n",
      "        [[-1.6019, -2.7578, -1.3270,  ...,  2.0451,  0.8733,  0.1474],\n",
      "         [ 0.4905,  0.6656,  0.0492,  ...,  0.6338,  1.1137,  1.1003],\n",
      "         [-0.3561, -1.4086, -0.0950,  ..., -0.4733, -0.3751,  0.9242],\n",
      "         [-0.1166,  0.5155, -0.5160,  ..., -1.3673, -1.0102, -1.5744],\n",
      "         [ 1.3232,  2.3769,  2.0724,  ..., -0.3279, -0.2706,  0.0154],\n",
      "         [ 0.2497,  0.6028, -0.3905,  ..., -1.0834, -0.6548, -0.8067]],\n",
      "\n",
      "        [[-0.0825, -0.2908,  0.0548,  ...,  0.8275,  0.3917,  0.2228],\n",
      "         [-0.1235,  0.3237,  0.4651,  ...,  0.3619,  0.9666,  0.7072],\n",
      "         [ 0.2111, -1.5614, -1.6469,  ...,  2.0298,  1.3807,  1.0165],\n",
      "         [ 0.1815,  0.6937,  0.8239,  ..., -1.5546, -0.8986, -0.1389],\n",
      "         [ 0.0523,  0.1525, -0.6557,  ...,  0.0079, -0.3877, -0.8675],\n",
      "         [-0.1745,  0.6241,  0.9120,  ..., -1.8570, -1.5698, -0.8948]]])\n"
     ]
    }
   ],
   "source": [
    "if show:\n",
    "    data_downsampled = downsample(data)\n",
    "    print(data_downsampled.shape, data_downsampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "15910017-71e7-4f44-bd43-27b953f9ad58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Never mind the warnings...\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"sklearn.base\")\n",
    "\n",
    "def ica(data, max_iter=1000, tol=1e-6):\n",
    "    results = []\n",
    "    for d in data:\n",
    "        d = d.transpose(0, 1)\n",
    "        transform = picard.Picard(d.size(1), max_iter=1000, tol=1e-6)\n",
    "        result = torch.tensor(transform.fit_transform(d),\n",
    "                              dtype=data.dtype,\n",
    "                              device=data.device).transpose(0, 1)\n",
    "        results.append(result)\n",
    "    return torch.stack(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ca265cda-d025-47fa-b5de-c783afc2d904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9315, 6, 512]) tensor([[ 0.0103, -0.0627, -0.0557,  ...,  0.0420,  0.0457,  0.0889],\n",
      "        [ 0.0667,  0.0152, -0.0047,  ...,  0.0820,  0.0873,  0.0897],\n",
      "        [ 0.0460,  0.0295, -0.0066,  ...,  0.0190,  0.0036,  0.0094],\n",
      "        [-0.0461, -0.0633, -0.0741,  ...,  0.0075, -0.0168, -0.0154],\n",
      "        [-0.0178, -0.0377,  0.0181,  ...,  0.0685,  0.0834,  0.0499],\n",
      "        [ 0.0052,  0.0203,  0.0342,  ..., -0.0011, -0.0159, -0.0094]])\n"
     ]
    }
   ],
   "source": [
    "if show:\n",
    "    y = ica(data_downsampled)\n",
    "    print(y.shape, y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7d99ad66-9ac7-42cf-89c3-8b4df28783d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This was provided by o1 based on the disussion here:\n",
    "# https://chatgpt.com/share/67669e9c-ebd8-8007-92f0-70579f58cc9a\n",
    "\n",
    "def ica_fit_and_transform(\n",
    "    data: torch.Tensor,      # shape [N, C, T]\n",
    "    train_mask: torch.Tensor,# shape [N], boolean or long indices\n",
    "    max_iter: int = 1000,\n",
    "    tol: float = 1e-6\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Learn a single ICA decomposition on all training-set trials, \n",
    "    then apply that unmixing to the entire dataset.\n",
    "\n",
    "    Args:\n",
    "        data (torch.Tensor): \n",
    "            EEG data of shape [num_trials, num_channels, num_timepoints].\n",
    "        train_mask (torch.Tensor): \n",
    "            Boolean or index mask of shape [num_trials] indicating which trials are training.\n",
    "        max_iter (int): \n",
    "            Maximum number of Picard iterations.\n",
    "        tol (float): \n",
    "            Tolerance for the stopping criterion in Picard.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: \n",
    "            ICA-transformed data of shape [num_trials, num_channels, num_timepoints].\n",
    "            Each trial has the same shape as input but in the ICA component space.\n",
    "    \"\"\"\n",
    "\n",
    "    device = data.device\n",
    "    dtype = data.dtype\n",
    "\n",
    "    # ------------------------------------------\n",
    "    # 1) EXTRACT & CONCATENATE ALL TRAINING TRIALS\n",
    "    # ------------------------------------------\n",
    "    # data[train_mask] has shape [n_train, C, T]\n",
    "    train_data = data[train_mask]\n",
    "    n_train, C, T = train_data.shape\n",
    "\n",
    "    # We want shape [n_samples, n_features] = [n_train*T, C]\n",
    "    # So permute to [n_train, T, C], then reshape\n",
    "    # => shape [n_train*T, C]\n",
    "    train_data_2d = train_data.permute(0, 2, 1).reshape(-1, C)\n",
    "\n",
    "    # Move to CPU if necessary, because Picard typically runs on NumPy\n",
    "    train_data_np = train_data_2d.cpu().numpy()\n",
    "\n",
    "    # ------------------------------------------\n",
    "    # 2) FIT ICA ON ALL TRAINING DATA\n",
    "    # ------------------------------------------\n",
    "    ica_transform = picard.Picard(\n",
    "        n_components=C, \n",
    "        max_iter=max_iter, \n",
    "        tol=tol\n",
    "    )\n",
    "    ica_transform.fit(train_data_np)\n",
    "\n",
    "    # ------------------------------------------\n",
    "    # 3) APPLY ICA TO ALL TRIALS (TRAIN/VAL/TEST)\n",
    "    # ------------------------------------------\n",
    "    results = []\n",
    "    N = data.shape[0]\n",
    "    for i in range(N):\n",
    "        # Each trial: shape [C, T]\n",
    "        trial = data[i]  \n",
    "        # Transpose to [T, C] for transform()\n",
    "        trial_t = trial.transpose(0, 1).cpu().numpy()\n",
    "\n",
    "        # Transform with the learned unmixing\n",
    "        trial_ica = ica_transform.transform(trial_t)  \n",
    "        # => shape [T, C]\n",
    "\n",
    "        # Convert back to Torch, and transpose to [C, T] if desired\n",
    "        trial_ica_torch = torch.tensor(\n",
    "            trial_ica, dtype=dtype, device=device\n",
    "        ).transpose(0, 1)\n",
    "\n",
    "        results.append(trial_ica_torch)\n",
    "\n",
    "    # Stack back into [N, C, T]\n",
    "    return torch.stack(results, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "acfb4c52-cca2-4e40-82bb-ba3e546e328e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9315, 6, 512]) tensor([[ 7.7457e-04,  5.2590e-04,  3.4034e-04,  ...,  4.3600e-04,\n",
      "          4.8140e-04,  6.1021e-04],\n",
      "        [-2.0970e-04,  2.6050e-04,  8.5429e-05,  ..., -7.0999e-05,\n",
      "         -2.7817e-04, -7.3878e-04],\n",
      "        [-4.4021e-04,  5.1835e-04,  1.0887e-03,  ..., -7.2686e-04,\n",
      "         -4.6791e-04, -8.5118e-04],\n",
      "        [-2.5562e-04,  7.5510e-05,  3.3148e-04,  ..., -1.4841e-05,\n",
      "          3.0130e-04, -2.7047e-04],\n",
      "        [-1.9194e-03, -1.8411e-03, -9.6671e-04,  ..., -2.4568e-04,\n",
      "         -2.1815e-04, -5.0176e-04],\n",
      "        [ 3.0886e-04, -2.6873e-04, -4.9061e-05,  ...,  9.5303e-04,\n",
      "          1.2210e-03,  1.0832e-03]])\n"
     ]
    }
   ],
   "source": [
    "if show:\n",
    "    train_mask = torch.rand((len(data_downsampled),)) < 0.8\n",
    "    z = ica_fit_and_transform(data_downsampled, train_mask=train_mask)\n",
    "    print(z.shape, z[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "16ab1956-bbdf-42e9-ad36-19c2f22dc185",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bandpass_filter(data, low=2, high=40, rate=1024, order=5):\n",
    "    sos = scipy.signal.butter(order, [low / rate / 2, high / rate / 2], btype='band', output='sos')\n",
    "    return torch.tensor(scipy.signal.sosfilt(sos, np.ascontiguousarray(data)), dtype=data.dtype, device=data.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "53345c62-156c-45f8-92bc-532427e8f64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9315, 6, 4096]) tensor([[-4.5239e-08, -4.8647e-07, -2.6267e-06,  ...,  7.2935e-01,\n",
      "          7.1904e-01,  7.0679e-01],\n",
      "        [-2.7523e-08, -2.9697e-07, -1.6099e-06,  ..., -3.5150e-02,\n",
      "         -3.9813e-02, -4.4669e-02],\n",
      "        [ 7.8006e-09,  8.3659e-08,  4.5010e-07,  ..., -1.0281e+00,\n",
      "         -1.0309e+00, -1.0312e+00],\n",
      "        [ 2.9645e-08,  3.1735e-07,  1.7043e-06,  ...,  4.2283e-01,\n",
      "          4.1938e-01,  4.1686e-01],\n",
      "        [ 3.3837e-08,  3.6639e-07,  1.9946e-06,  ..., -4.5932e-01,\n",
      "         -4.5563e-01, -4.5226e-01],\n",
      "        [ 3.7081e-08,  3.9848e-07,  2.1501e-06,  ...,  5.1451e-02,\n",
      "          7.4699e-02,  9.8546e-02]])\n"
     ]
    }
   ],
   "source": [
    "if show:\n",
    "    a = bandpass_filter(data)\n",
    "    print(a.shape, a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8a2b26e3-89e6-4bae-9369-da9f867a2a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def robust_scaler(data):\n",
    "    scaled = sklearn.preprocessing.RobustScaler().fit_transform(data.cpu().numpy().reshape(-1, data.shape[-1]))\n",
    "    return torch.tensor(scaled.reshape(data.shape), dtype=data.dtype, device=data.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "969c49d9-9d00-4384-87ca-dcb6f18b7265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9315, 6, 4096]) tensor([[-1.7777, -1.6704, -1.5620,  ..., -0.9362, -0.9044, -0.8454],\n",
      "        [-1.0794, -1.0530, -1.0252,  ...,  0.1270,  0.0442, -0.0486],\n",
      "        [ 0.3131,  0.2875,  0.2523,  ..., -0.1105, -0.1279, -0.1621],\n",
      "        [ 1.1742,  1.0497,  0.9236,  ...,  1.6232,  1.5689,  1.5189],\n",
      "        [ 1.3394,  1.3612,  1.3808,  ..., -0.8492, -0.7490, -0.6496],\n",
      "        [ 1.4673,  1.3717,  1.2776,  ...,  1.1639,  1.1454,  1.1282]])\n"
     ]
    }
   ],
   "source": [
    "if show:\n",
    "    b = robust_scaler(data)\n",
    "    print(b.shape, b[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39f0610-7a79-46c5-b385-7a688bae300c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
